# Home Sales

Used pyspark to analyze metric from home sales data.  Spark was used to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached.

As pyspark and spark were installed on a local machine, google collab was not used, thus, any effects of cacheing data were not noticeable as all lines of code ran fairly quickly.
